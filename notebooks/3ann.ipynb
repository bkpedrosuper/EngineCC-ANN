{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network Build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets build an artificial neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from config import MAIN_PALETTE\n",
    "\n",
    "sns.set_theme(context='notebook', style='whitegrid', palette='bright', font='sans-serif', \n",
    "                  font_scale=1, color_codes=True, rc=None)\n",
    "plt.rcParams[\"figure.figsize\"] = (15,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_201</th>\n",
       "      <th>current_202</th>\n",
       "      <th>current_203</th>\n",
       "      <th>current_204</th>\n",
       "      <th>current_205</th>\n",
       "      <th>current_206</th>\n",
       "      <th>current_207</th>\n",
       "      <th>current_208</th>\n",
       "      <th>current_209</th>\n",
       "      <th>current_210</th>\n",
       "      <th>...</th>\n",
       "      <th>volt_792</th>\n",
       "      <th>volt_793</th>\n",
       "      <th>volt_794</th>\n",
       "      <th>volt_795</th>\n",
       "      <th>volt_796</th>\n",
       "      <th>volt_797</th>\n",
       "      <th>volt_798</th>\n",
       "      <th>volt_799</th>\n",
       "      <th>volt_800</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.682921</td>\n",
       "      <td>0.682195</td>\n",
       "      <td>0.681640</td>\n",
       "      <td>0.681171</td>\n",
       "      <td>0.680729</td>\n",
       "      <td>0.680484</td>\n",
       "      <td>0.680928</td>\n",
       "      <td>0.682209</td>\n",
       "      <td>0.683694</td>\n",
       "      <td>0.684659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.406982</td>\n",
       "      <td>0.367278</td>\n",
       "      <td>0.364093</td>\n",
       "      <td>0.402194</td>\n",
       "      <td>0.448523</td>\n",
       "      <td>0.450469</td>\n",
       "      <td>0.356803</td>\n",
       "      <td>0.302953</td>\n",
       "      <td>0.274347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.679731</td>\n",
       "      <td>0.678763</td>\n",
       "      <td>0.678157</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.678474</td>\n",
       "      <td>0.679554</td>\n",
       "      <td>0.680862</td>\n",
       "      <td>0.681912</td>\n",
       "      <td>0.682436</td>\n",
       "      <td>0.682467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273656</td>\n",
       "      <td>0.261276</td>\n",
       "      <td>0.271836</td>\n",
       "      <td>0.308600</td>\n",
       "      <td>0.356592</td>\n",
       "      <td>0.389055</td>\n",
       "      <td>0.355631</td>\n",
       "      <td>0.369090</td>\n",
       "      <td>0.410403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.692921</td>\n",
       "      <td>0.692640</td>\n",
       "      <td>0.692082</td>\n",
       "      <td>0.691222</td>\n",
       "      <td>0.690065</td>\n",
       "      <td>0.688761</td>\n",
       "      <td>0.687545</td>\n",
       "      <td>0.686558</td>\n",
       "      <td>0.685798</td>\n",
       "      <td>0.685337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317711</td>\n",
       "      <td>0.297014</td>\n",
       "      <td>0.288137</td>\n",
       "      <td>0.302547</td>\n",
       "      <td>0.330311</td>\n",
       "      <td>0.342483</td>\n",
       "      <td>0.289035</td>\n",
       "      <td>0.271342</td>\n",
       "      <td>0.278585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.684316</td>\n",
       "      <td>0.684550</td>\n",
       "      <td>0.684634</td>\n",
       "      <td>0.684632</td>\n",
       "      <td>0.684461</td>\n",
       "      <td>0.683996</td>\n",
       "      <td>0.683266</td>\n",
       "      <td>0.682420</td>\n",
       "      <td>0.681621</td>\n",
       "      <td>0.680988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265779</td>\n",
       "      <td>0.276489</td>\n",
       "      <td>0.310451</td>\n",
       "      <td>0.382017</td>\n",
       "      <td>0.485955</td>\n",
       "      <td>0.568265</td>\n",
       "      <td>0.505633</td>\n",
       "      <td>0.450684</td>\n",
       "      <td>0.407461</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.671236</td>\n",
       "      <td>0.670445</td>\n",
       "      <td>0.669661</td>\n",
       "      <td>0.668889</td>\n",
       "      <td>0.668196</td>\n",
       "      <td>0.667722</td>\n",
       "      <td>0.667399</td>\n",
       "      <td>0.667360</td>\n",
       "      <td>0.668124</td>\n",
       "      <td>0.669890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415693</td>\n",
       "      <td>0.381110</td>\n",
       "      <td>0.376050</td>\n",
       "      <td>0.407861</td>\n",
       "      <td>0.460601</td>\n",
       "      <td>0.481486</td>\n",
       "      <td>0.389891</td>\n",
       "      <td>0.325563</td>\n",
       "      <td>0.281171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.655160</td>\n",
       "      <td>0.654703</td>\n",
       "      <td>0.654392</td>\n",
       "      <td>0.654158</td>\n",
       "      <td>0.654086</td>\n",
       "      <td>0.654370</td>\n",
       "      <td>0.655265</td>\n",
       "      <td>0.656777</td>\n",
       "      <td>0.658473</td>\n",
       "      <td>0.659922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085348</td>\n",
       "      <td>0.067686</td>\n",
       "      <td>0.062863</td>\n",
       "      <td>0.078773</td>\n",
       "      <td>0.102914</td>\n",
       "      <td>0.117693</td>\n",
       "      <td>0.097859</td>\n",
       "      <td>0.085690</td>\n",
       "      <td>0.079646</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.688720</td>\n",
       "      <td>0.691066</td>\n",
       "      <td>0.693366</td>\n",
       "      <td>0.695296</td>\n",
       "      <td>0.696822</td>\n",
       "      <td>0.698040</td>\n",
       "      <td>0.699004</td>\n",
       "      <td>0.699738</td>\n",
       "      <td>0.700179</td>\n",
       "      <td>0.700178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243962</td>\n",
       "      <td>0.250543</td>\n",
       "      <td>0.279990</td>\n",
       "      <td>0.333953</td>\n",
       "      <td>0.393716</td>\n",
       "      <td>0.419058</td>\n",
       "      <td>0.355549</td>\n",
       "      <td>0.327488</td>\n",
       "      <td>0.312347</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.717838</td>\n",
       "      <td>0.716938</td>\n",
       "      <td>0.715976</td>\n",
       "      <td>0.714911</td>\n",
       "      <td>0.713888</td>\n",
       "      <td>0.712956</td>\n",
       "      <td>0.711976</td>\n",
       "      <td>0.710904</td>\n",
       "      <td>0.709947</td>\n",
       "      <td>0.709364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269906</td>\n",
       "      <td>0.262787</td>\n",
       "      <td>0.261464</td>\n",
       "      <td>0.268023</td>\n",
       "      <td>0.270470</td>\n",
       "      <td>0.250558</td>\n",
       "      <td>0.187487</td>\n",
       "      <td>0.160850</td>\n",
       "      <td>0.156544</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.671228</td>\n",
       "      <td>0.671696</td>\n",
       "      <td>0.671971</td>\n",
       "      <td>0.672160</td>\n",
       "      <td>0.672397</td>\n",
       "      <td>0.672658</td>\n",
       "      <td>0.672790</td>\n",
       "      <td>0.672632</td>\n",
       "      <td>0.672193</td>\n",
       "      <td>0.671623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143442</td>\n",
       "      <td>0.139477</td>\n",
       "      <td>0.127960</td>\n",
       "      <td>0.122262</td>\n",
       "      <td>0.118875</td>\n",
       "      <td>0.110584</td>\n",
       "      <td>0.083422</td>\n",
       "      <td>0.073359</td>\n",
       "      <td>0.071337</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.722550</td>\n",
       "      <td>0.721452</td>\n",
       "      <td>0.720337</td>\n",
       "      <td>0.719178</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.716881</td>\n",
       "      <td>0.715988</td>\n",
       "      <td>0.715285</td>\n",
       "      <td>0.714784</td>\n",
       "      <td>0.714635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158205</td>\n",
       "      <td>0.208111</td>\n",
       "      <td>0.335710</td>\n",
       "      <td>0.476410</td>\n",
       "      <td>0.531009</td>\n",
       "      <td>0.470152</td>\n",
       "      <td>0.308952</td>\n",
       "      <td>0.213821</td>\n",
       "      <td>0.165598</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479 rows × 1201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     current_201  current_202  current_203  current_204  current_205  \\\n",
       "0       0.682921     0.682195     0.681640     0.681171     0.680729   \n",
       "1       0.679731     0.678763     0.678157     0.678000     0.678474   \n",
       "2       0.692921     0.692640     0.692082     0.691222     0.690065   \n",
       "3       0.684316     0.684550     0.684634     0.684632     0.684461   \n",
       "4       0.671236     0.670445     0.669661     0.668889     0.668196   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "474     0.655160     0.654703     0.654392     0.654158     0.654086   \n",
       "475     0.688720     0.691066     0.693366     0.695296     0.696822   \n",
       "476     0.717838     0.716938     0.715976     0.714911     0.713888   \n",
       "477     0.671228     0.671696     0.671971     0.672160     0.672397   \n",
       "478     0.722550     0.721452     0.720337     0.719178     0.717978   \n",
       "\n",
       "     current_206  current_207  current_208  current_209  current_210  ...  \\\n",
       "0       0.680484     0.680928     0.682209     0.683694     0.684659  ...   \n",
       "1       0.679554     0.680862     0.681912     0.682436     0.682467  ...   \n",
       "2       0.688761     0.687545     0.686558     0.685798     0.685337  ...   \n",
       "3       0.683996     0.683266     0.682420     0.681621     0.680988  ...   \n",
       "4       0.667722     0.667399     0.667360     0.668124     0.669890  ...   \n",
       "..           ...          ...          ...          ...          ...  ...   \n",
       "474     0.654370     0.655265     0.656777     0.658473     0.659922  ...   \n",
       "475     0.698040     0.699004     0.699738     0.700179     0.700178  ...   \n",
       "476     0.712956     0.711976     0.710904     0.709947     0.709364  ...   \n",
       "477     0.672658     0.672790     0.672632     0.672193     0.671623  ...   \n",
       "478     0.716881     0.715988     0.715285     0.714784     0.714635  ...   \n",
       "\n",
       "     volt_792  volt_793  volt_794  volt_795  volt_796  volt_797  volt_798  \\\n",
       "0    0.406982  0.367278  0.364093  0.402194  0.448523  0.450469  0.356803   \n",
       "1    0.273656  0.261276  0.271836  0.308600  0.356592  0.389055  0.355631   \n",
       "2    0.317711  0.297014  0.288137  0.302547  0.330311  0.342483  0.289035   \n",
       "3    0.265779  0.276489  0.310451  0.382017  0.485955  0.568265  0.505633   \n",
       "4    0.415693  0.381110  0.376050  0.407861  0.460601  0.481486  0.389891   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "474  0.085348  0.067686  0.062863  0.078773  0.102914  0.117693  0.097859   \n",
       "475  0.243962  0.250543  0.279990  0.333953  0.393716  0.419058  0.355549   \n",
       "476  0.269906  0.262787  0.261464  0.268023  0.270470  0.250558  0.187487   \n",
       "477  0.143442  0.139477  0.127960  0.122262  0.118875  0.110584  0.083422   \n",
       "478  0.158205  0.208111  0.335710  0.476410  0.531009  0.470152  0.308952   \n",
       "\n",
       "     volt_799  volt_800  state  \n",
       "0    0.302953  0.274347      0  \n",
       "1    0.369090  0.410403      0  \n",
       "2    0.271342  0.278585      0  \n",
       "3    0.450684  0.407461      0  \n",
       "4    0.325563  0.281171      0  \n",
       "..        ...       ...    ...  \n",
       "474  0.085690  0.079646      2  \n",
       "475  0.327488  0.312347      2  \n",
       "476  0.160850  0.156544      2  \n",
       "477  0.073359  0.071337      2  \n",
       "478  0.213821  0.165598      2  \n",
       "\n",
       "[479 rows x 1201 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/dataset_cleaned.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_201</th>\n",
       "      <th>current_202</th>\n",
       "      <th>current_203</th>\n",
       "      <th>current_204</th>\n",
       "      <th>current_205</th>\n",
       "      <th>current_206</th>\n",
       "      <th>current_207</th>\n",
       "      <th>current_208</th>\n",
       "      <th>current_209</th>\n",
       "      <th>current_210</th>\n",
       "      <th>...</th>\n",
       "      <th>volt_791</th>\n",
       "      <th>volt_792</th>\n",
       "      <th>volt_793</th>\n",
       "      <th>volt_794</th>\n",
       "      <th>volt_795</th>\n",
       "      <th>volt_796</th>\n",
       "      <th>volt_797</th>\n",
       "      <th>volt_798</th>\n",
       "      <th>volt_799</th>\n",
       "      <th>volt_800</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.682921</td>\n",
       "      <td>0.682195</td>\n",
       "      <td>0.681640</td>\n",
       "      <td>0.681171</td>\n",
       "      <td>0.680729</td>\n",
       "      <td>0.680484</td>\n",
       "      <td>0.680928</td>\n",
       "      <td>0.682209</td>\n",
       "      <td>0.683694</td>\n",
       "      <td>0.684659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475171</td>\n",
       "      <td>0.406982</td>\n",
       "      <td>0.367278</td>\n",
       "      <td>0.364093</td>\n",
       "      <td>0.402194</td>\n",
       "      <td>0.448523</td>\n",
       "      <td>0.450469</td>\n",
       "      <td>0.356803</td>\n",
       "      <td>0.302953</td>\n",
       "      <td>0.274347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.679731</td>\n",
       "      <td>0.678763</td>\n",
       "      <td>0.678157</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.678474</td>\n",
       "      <td>0.679554</td>\n",
       "      <td>0.680862</td>\n",
       "      <td>0.681912</td>\n",
       "      <td>0.682436</td>\n",
       "      <td>0.682467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313650</td>\n",
       "      <td>0.273656</td>\n",
       "      <td>0.261276</td>\n",
       "      <td>0.271836</td>\n",
       "      <td>0.308600</td>\n",
       "      <td>0.356592</td>\n",
       "      <td>0.389055</td>\n",
       "      <td>0.355631</td>\n",
       "      <td>0.369090</td>\n",
       "      <td>0.410403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.692921</td>\n",
       "      <td>0.692640</td>\n",
       "      <td>0.692082</td>\n",
       "      <td>0.691222</td>\n",
       "      <td>0.690065</td>\n",
       "      <td>0.688761</td>\n",
       "      <td>0.687545</td>\n",
       "      <td>0.686558</td>\n",
       "      <td>0.685798</td>\n",
       "      <td>0.685337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346655</td>\n",
       "      <td>0.317711</td>\n",
       "      <td>0.297014</td>\n",
       "      <td>0.288137</td>\n",
       "      <td>0.302547</td>\n",
       "      <td>0.330311</td>\n",
       "      <td>0.342483</td>\n",
       "      <td>0.289035</td>\n",
       "      <td>0.271342</td>\n",
       "      <td>0.278585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.684316</td>\n",
       "      <td>0.684550</td>\n",
       "      <td>0.684634</td>\n",
       "      <td>0.684632</td>\n",
       "      <td>0.684461</td>\n",
       "      <td>0.683996</td>\n",
       "      <td>0.683266</td>\n",
       "      <td>0.682420</td>\n",
       "      <td>0.681621</td>\n",
       "      <td>0.680988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277664</td>\n",
       "      <td>0.265779</td>\n",
       "      <td>0.276489</td>\n",
       "      <td>0.310451</td>\n",
       "      <td>0.382017</td>\n",
       "      <td>0.485955</td>\n",
       "      <td>0.568265</td>\n",
       "      <td>0.505633</td>\n",
       "      <td>0.450684</td>\n",
       "      <td>0.407461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.671236</td>\n",
       "      <td>0.670445</td>\n",
       "      <td>0.669661</td>\n",
       "      <td>0.668889</td>\n",
       "      <td>0.668196</td>\n",
       "      <td>0.667722</td>\n",
       "      <td>0.667399</td>\n",
       "      <td>0.667360</td>\n",
       "      <td>0.668124</td>\n",
       "      <td>0.669890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474643</td>\n",
       "      <td>0.415693</td>\n",
       "      <td>0.381110</td>\n",
       "      <td>0.376050</td>\n",
       "      <td>0.407861</td>\n",
       "      <td>0.460601</td>\n",
       "      <td>0.481486</td>\n",
       "      <td>0.389891</td>\n",
       "      <td>0.325563</td>\n",
       "      <td>0.281171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.655160</td>\n",
       "      <td>0.654703</td>\n",
       "      <td>0.654392</td>\n",
       "      <td>0.654158</td>\n",
       "      <td>0.654086</td>\n",
       "      <td>0.654370</td>\n",
       "      <td>0.655265</td>\n",
       "      <td>0.656777</td>\n",
       "      <td>0.658473</td>\n",
       "      <td>0.659922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118411</td>\n",
       "      <td>0.085348</td>\n",
       "      <td>0.067686</td>\n",
       "      <td>0.062863</td>\n",
       "      <td>0.078773</td>\n",
       "      <td>0.102914</td>\n",
       "      <td>0.117693</td>\n",
       "      <td>0.097859</td>\n",
       "      <td>0.085690</td>\n",
       "      <td>0.079646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.688720</td>\n",
       "      <td>0.691066</td>\n",
       "      <td>0.693366</td>\n",
       "      <td>0.695296</td>\n",
       "      <td>0.696822</td>\n",
       "      <td>0.698040</td>\n",
       "      <td>0.699004</td>\n",
       "      <td>0.699738</td>\n",
       "      <td>0.700179</td>\n",
       "      <td>0.700178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267515</td>\n",
       "      <td>0.243962</td>\n",
       "      <td>0.250543</td>\n",
       "      <td>0.279990</td>\n",
       "      <td>0.333953</td>\n",
       "      <td>0.393716</td>\n",
       "      <td>0.419058</td>\n",
       "      <td>0.355549</td>\n",
       "      <td>0.327488</td>\n",
       "      <td>0.312347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.717838</td>\n",
       "      <td>0.716938</td>\n",
       "      <td>0.715976</td>\n",
       "      <td>0.714911</td>\n",
       "      <td>0.713888</td>\n",
       "      <td>0.712956</td>\n",
       "      <td>0.711976</td>\n",
       "      <td>0.710904</td>\n",
       "      <td>0.709947</td>\n",
       "      <td>0.709364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300854</td>\n",
       "      <td>0.269906</td>\n",
       "      <td>0.262787</td>\n",
       "      <td>0.261464</td>\n",
       "      <td>0.268023</td>\n",
       "      <td>0.270470</td>\n",
       "      <td>0.250558</td>\n",
       "      <td>0.187487</td>\n",
       "      <td>0.160850</td>\n",
       "      <td>0.156544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.671228</td>\n",
       "      <td>0.671696</td>\n",
       "      <td>0.671971</td>\n",
       "      <td>0.672160</td>\n",
       "      <td>0.672397</td>\n",
       "      <td>0.672658</td>\n",
       "      <td>0.672790</td>\n",
       "      <td>0.672632</td>\n",
       "      <td>0.672193</td>\n",
       "      <td>0.671623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149968</td>\n",
       "      <td>0.143442</td>\n",
       "      <td>0.139477</td>\n",
       "      <td>0.127960</td>\n",
       "      <td>0.122262</td>\n",
       "      <td>0.118875</td>\n",
       "      <td>0.110584</td>\n",
       "      <td>0.083422</td>\n",
       "      <td>0.073359</td>\n",
       "      <td>0.071337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.722550</td>\n",
       "      <td>0.721452</td>\n",
       "      <td>0.720337</td>\n",
       "      <td>0.719178</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.716881</td>\n",
       "      <td>0.715988</td>\n",
       "      <td>0.715285</td>\n",
       "      <td>0.714784</td>\n",
       "      <td>0.714635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169253</td>\n",
       "      <td>0.158205</td>\n",
       "      <td>0.208111</td>\n",
       "      <td>0.335710</td>\n",
       "      <td>0.476410</td>\n",
       "      <td>0.531009</td>\n",
       "      <td>0.470152</td>\n",
       "      <td>0.308952</td>\n",
       "      <td>0.213821</td>\n",
       "      <td>0.165598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479 rows × 1200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     current_201  current_202  current_203  current_204  current_205  \\\n",
       "0       0.682921     0.682195     0.681640     0.681171     0.680729   \n",
       "1       0.679731     0.678763     0.678157     0.678000     0.678474   \n",
       "2       0.692921     0.692640     0.692082     0.691222     0.690065   \n",
       "3       0.684316     0.684550     0.684634     0.684632     0.684461   \n",
       "4       0.671236     0.670445     0.669661     0.668889     0.668196   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "474     0.655160     0.654703     0.654392     0.654158     0.654086   \n",
       "475     0.688720     0.691066     0.693366     0.695296     0.696822   \n",
       "476     0.717838     0.716938     0.715976     0.714911     0.713888   \n",
       "477     0.671228     0.671696     0.671971     0.672160     0.672397   \n",
       "478     0.722550     0.721452     0.720337     0.719178     0.717978   \n",
       "\n",
       "     current_206  current_207  current_208  current_209  current_210  ...  \\\n",
       "0       0.680484     0.680928     0.682209     0.683694     0.684659  ...   \n",
       "1       0.679554     0.680862     0.681912     0.682436     0.682467  ...   \n",
       "2       0.688761     0.687545     0.686558     0.685798     0.685337  ...   \n",
       "3       0.683996     0.683266     0.682420     0.681621     0.680988  ...   \n",
       "4       0.667722     0.667399     0.667360     0.668124     0.669890  ...   \n",
       "..           ...          ...          ...          ...          ...  ...   \n",
       "474     0.654370     0.655265     0.656777     0.658473     0.659922  ...   \n",
       "475     0.698040     0.699004     0.699738     0.700179     0.700178  ...   \n",
       "476     0.712956     0.711976     0.710904     0.709947     0.709364  ...   \n",
       "477     0.672658     0.672790     0.672632     0.672193     0.671623  ...   \n",
       "478     0.716881     0.715988     0.715285     0.714784     0.714635  ...   \n",
       "\n",
       "     volt_791  volt_792  volt_793  volt_794  volt_795  volt_796  volt_797  \\\n",
       "0    0.475171  0.406982  0.367278  0.364093  0.402194  0.448523  0.450469   \n",
       "1    0.313650  0.273656  0.261276  0.271836  0.308600  0.356592  0.389055   \n",
       "2    0.346655  0.317711  0.297014  0.288137  0.302547  0.330311  0.342483   \n",
       "3    0.277664  0.265779  0.276489  0.310451  0.382017  0.485955  0.568265   \n",
       "4    0.474643  0.415693  0.381110  0.376050  0.407861  0.460601  0.481486   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "474  0.118411  0.085348  0.067686  0.062863  0.078773  0.102914  0.117693   \n",
       "475  0.267515  0.243962  0.250543  0.279990  0.333953  0.393716  0.419058   \n",
       "476  0.300854  0.269906  0.262787  0.261464  0.268023  0.270470  0.250558   \n",
       "477  0.149968  0.143442  0.139477  0.127960  0.122262  0.118875  0.110584   \n",
       "478  0.169253  0.158205  0.208111  0.335710  0.476410  0.531009  0.470152   \n",
       "\n",
       "     volt_798  volt_799  volt_800  \n",
       "0    0.356803  0.302953  0.274347  \n",
       "1    0.355631  0.369090  0.410403  \n",
       "2    0.289035  0.271342  0.278585  \n",
       "3    0.505633  0.450684  0.407461  \n",
       "4    0.389891  0.325563  0.281171  \n",
       "..        ...       ...       ...  \n",
       "474  0.097859  0.085690  0.079646  \n",
       "475  0.355549  0.327488  0.312347  \n",
       "476  0.187487  0.160850  0.156544  \n",
       "477  0.083422  0.073359  0.071337  \n",
       "478  0.308952  0.213821  0.165598  \n",
       "\n",
       "[479 rows x 1200 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = data.iloc[:, :-1], data.iloc[:, -1]\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the best training and testing datasets, we're going to balance the amount of each state.\n",
    "We're going to use:\n",
    "\n",
    "Training:\n",
    "120 from state 0\n",
    "85 from state 1\n",
    "85 from state 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State 0 shape: (288, 1201)\n",
      "State 1 shape: (97, 1201)\n",
      "State 2 shape: (94, 1201)\n"
     ]
    }
   ],
   "source": [
    "df_0 = data.query('state == 0')\n",
    "df_1 = data.query('state == 1')\n",
    "df_2 = data.query('state == 2')\n",
    "\n",
    "print('State 0 shape:', df_0.shape)\n",
    "print('State 1 shape:', df_1.shape)\n",
    "print('State 2 shape:', df_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape (184, 1200)\n",
      "y_test shape (184,)\n",
      "==========\n",
      "X_train shape (295, 1200)\n",
      "y_train shape (295,)\n"
     ]
    }
   ],
   "source": [
    "state0_train_size = 125\n",
    "state1_train_size = 85\n",
    "state2_train_size = 85\n",
    "\n",
    "# state 0\n",
    "X_train_0 = df_0.iloc[:state0_train_size, :-1]\n",
    "X_test_0 = df_0.iloc[state0_train_size:, :-1]\n",
    "\n",
    "y_train_0 = df_0.iloc[:state0_train_size, -1]\n",
    "y_test_0 = df_0.iloc[state0_train_size:, -1]\n",
    "\n",
    "# state 1\n",
    "X_train_1 = df_1.iloc[:state1_train_size, :-1]\n",
    "X_test_1 = df_1.iloc[state1_train_size:, :-1]\n",
    "\n",
    "y_train_1 = df_1.iloc[:state1_train_size, -1]\n",
    "y_test_1 = df_1.iloc[state1_train_size:, -1]\n",
    "\n",
    "# state 2\n",
    "X_train_2 = df_2.iloc[:state2_train_size, :-1]\n",
    "X_test_2 = df_2.iloc[state2_train_size:, :-1]\n",
    "\n",
    "y_train_2 = df_2.iloc[:state2_train_size, -1]\n",
    "y_test_2 = df_2.iloc[state2_train_size:, -1]\n",
    "\n",
    "# Concatenate\n",
    "X_train = pd.concat([X_train_0, X_train_1, X_train_2])\n",
    "X_test = pd.concat([X_test_0, X_test_1, X_test_2])\n",
    "\n",
    "y_train = pd.concat([y_train_0, y_train_1, y_train_2])\n",
    "y_test = pd.concat([y_test_0, y_test_1, y_test_2])\n",
    "\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)\n",
    "print(\"==========\")\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_201</th>\n",
       "      <th>current_202</th>\n",
       "      <th>current_203</th>\n",
       "      <th>current_204</th>\n",
       "      <th>current_205</th>\n",
       "      <th>current_206</th>\n",
       "      <th>current_207</th>\n",
       "      <th>current_208</th>\n",
       "      <th>current_209</th>\n",
       "      <th>current_210</th>\n",
       "      <th>...</th>\n",
       "      <th>volt_791</th>\n",
       "      <th>volt_792</th>\n",
       "      <th>volt_793</th>\n",
       "      <th>volt_794</th>\n",
       "      <th>volt_795</th>\n",
       "      <th>volt_796</th>\n",
       "      <th>volt_797</th>\n",
       "      <th>volt_798</th>\n",
       "      <th>volt_799</th>\n",
       "      <th>volt_800</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.682921</td>\n",
       "      <td>0.682195</td>\n",
       "      <td>0.681640</td>\n",
       "      <td>0.681171</td>\n",
       "      <td>0.680729</td>\n",
       "      <td>0.680484</td>\n",
       "      <td>0.680928</td>\n",
       "      <td>0.682209</td>\n",
       "      <td>0.683694</td>\n",
       "      <td>0.684659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475171</td>\n",
       "      <td>0.406982</td>\n",
       "      <td>0.367278</td>\n",
       "      <td>0.364093</td>\n",
       "      <td>0.402194</td>\n",
       "      <td>0.448523</td>\n",
       "      <td>0.450469</td>\n",
       "      <td>0.356803</td>\n",
       "      <td>0.302953</td>\n",
       "      <td>0.274347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.679731</td>\n",
       "      <td>0.678763</td>\n",
       "      <td>0.678157</td>\n",
       "      <td>0.678000</td>\n",
       "      <td>0.678474</td>\n",
       "      <td>0.679554</td>\n",
       "      <td>0.680862</td>\n",
       "      <td>0.681912</td>\n",
       "      <td>0.682436</td>\n",
       "      <td>0.682467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313650</td>\n",
       "      <td>0.273656</td>\n",
       "      <td>0.261276</td>\n",
       "      <td>0.271836</td>\n",
       "      <td>0.308600</td>\n",
       "      <td>0.356592</td>\n",
       "      <td>0.389055</td>\n",
       "      <td>0.355631</td>\n",
       "      <td>0.369090</td>\n",
       "      <td>0.410403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.692921</td>\n",
       "      <td>0.692640</td>\n",
       "      <td>0.692082</td>\n",
       "      <td>0.691222</td>\n",
       "      <td>0.690065</td>\n",
       "      <td>0.688761</td>\n",
       "      <td>0.687545</td>\n",
       "      <td>0.686558</td>\n",
       "      <td>0.685798</td>\n",
       "      <td>0.685337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346655</td>\n",
       "      <td>0.317711</td>\n",
       "      <td>0.297014</td>\n",
       "      <td>0.288137</td>\n",
       "      <td>0.302547</td>\n",
       "      <td>0.330311</td>\n",
       "      <td>0.342483</td>\n",
       "      <td>0.289035</td>\n",
       "      <td>0.271342</td>\n",
       "      <td>0.278585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.684316</td>\n",
       "      <td>0.684550</td>\n",
       "      <td>0.684634</td>\n",
       "      <td>0.684632</td>\n",
       "      <td>0.684461</td>\n",
       "      <td>0.683996</td>\n",
       "      <td>0.683266</td>\n",
       "      <td>0.682420</td>\n",
       "      <td>0.681621</td>\n",
       "      <td>0.680988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277664</td>\n",
       "      <td>0.265779</td>\n",
       "      <td>0.276489</td>\n",
       "      <td>0.310451</td>\n",
       "      <td>0.382017</td>\n",
       "      <td>0.485955</td>\n",
       "      <td>0.568265</td>\n",
       "      <td>0.505633</td>\n",
       "      <td>0.450684</td>\n",
       "      <td>0.407461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.671236</td>\n",
       "      <td>0.670445</td>\n",
       "      <td>0.669661</td>\n",
       "      <td>0.668889</td>\n",
       "      <td>0.668196</td>\n",
       "      <td>0.667722</td>\n",
       "      <td>0.667399</td>\n",
       "      <td>0.667360</td>\n",
       "      <td>0.668124</td>\n",
       "      <td>0.669890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474643</td>\n",
       "      <td>0.415693</td>\n",
       "      <td>0.381110</td>\n",
       "      <td>0.376050</td>\n",
       "      <td>0.407861</td>\n",
       "      <td>0.460601</td>\n",
       "      <td>0.481486</td>\n",
       "      <td>0.389891</td>\n",
       "      <td>0.325563</td>\n",
       "      <td>0.281171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0.699013</td>\n",
       "      <td>0.700283</td>\n",
       "      <td>0.701001</td>\n",
       "      <td>0.701229</td>\n",
       "      <td>0.701127</td>\n",
       "      <td>0.700915</td>\n",
       "      <td>0.700716</td>\n",
       "      <td>0.700710</td>\n",
       "      <td>0.700854</td>\n",
       "      <td>0.700750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164359</td>\n",
       "      <td>0.156490</td>\n",
       "      <td>0.160885</td>\n",
       "      <td>0.174962</td>\n",
       "      <td>0.209262</td>\n",
       "      <td>0.245508</td>\n",
       "      <td>0.258957</td>\n",
       "      <td>0.223890</td>\n",
       "      <td>0.225651</td>\n",
       "      <td>0.280271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0.693254</td>\n",
       "      <td>0.693763</td>\n",
       "      <td>0.694442</td>\n",
       "      <td>0.695615</td>\n",
       "      <td>0.697754</td>\n",
       "      <td>0.700593</td>\n",
       "      <td>0.703291</td>\n",
       "      <td>0.705338</td>\n",
       "      <td>0.706631</td>\n",
       "      <td>0.707332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335628</td>\n",
       "      <td>0.430326</td>\n",
       "      <td>0.492045</td>\n",
       "      <td>0.491282</td>\n",
       "      <td>0.453160</td>\n",
       "      <td>0.393129</td>\n",
       "      <td>0.308887</td>\n",
       "      <td>0.198685</td>\n",
       "      <td>0.149238</td>\n",
       "      <td>0.125311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0.686958</td>\n",
       "      <td>0.686474</td>\n",
       "      <td>0.685674</td>\n",
       "      <td>0.684757</td>\n",
       "      <td>0.683837</td>\n",
       "      <td>0.683164</td>\n",
       "      <td>0.682842</td>\n",
       "      <td>0.682819</td>\n",
       "      <td>0.683196</td>\n",
       "      <td>0.683973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173705</td>\n",
       "      <td>0.166870</td>\n",
       "      <td>0.171276</td>\n",
       "      <td>0.188868</td>\n",
       "      <td>0.235896</td>\n",
       "      <td>0.324066</td>\n",
       "      <td>0.461164</td>\n",
       "      <td>0.508763</td>\n",
       "      <td>0.510587</td>\n",
       "      <td>0.458503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0.652792</td>\n",
       "      <td>0.653381</td>\n",
       "      <td>0.654533</td>\n",
       "      <td>0.656147</td>\n",
       "      <td>0.657785</td>\n",
       "      <td>0.659059</td>\n",
       "      <td>0.659839</td>\n",
       "      <td>0.660204</td>\n",
       "      <td>0.660300</td>\n",
       "      <td>0.660191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193938</td>\n",
       "      <td>0.162887</td>\n",
       "      <td>0.151263</td>\n",
       "      <td>0.158412</td>\n",
       "      <td>0.186152</td>\n",
       "      <td>0.202066</td>\n",
       "      <td>0.179934</td>\n",
       "      <td>0.118501</td>\n",
       "      <td>0.085939</td>\n",
       "      <td>0.069742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>0.739684</td>\n",
       "      <td>0.740548</td>\n",
       "      <td>0.741296</td>\n",
       "      <td>0.741795</td>\n",
       "      <td>0.742056</td>\n",
       "      <td>0.742149</td>\n",
       "      <td>0.742147</td>\n",
       "      <td>0.742174</td>\n",
       "      <td>0.742341</td>\n",
       "      <td>0.742520</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348637</td>\n",
       "      <td>0.317461</td>\n",
       "      <td>0.309872</td>\n",
       "      <td>0.324136</td>\n",
       "      <td>0.363829</td>\n",
       "      <td>0.413066</td>\n",
       "      <td>0.431430</td>\n",
       "      <td>0.352381</td>\n",
       "      <td>0.300207</td>\n",
       "      <td>0.265476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows × 1200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     current_201  current_202  current_203  current_204  current_205  \\\n",
       "0       0.682921     0.682195     0.681640     0.681171     0.680729   \n",
       "1       0.679731     0.678763     0.678157     0.678000     0.678474   \n",
       "2       0.692921     0.692640     0.692082     0.691222     0.690065   \n",
       "3       0.684316     0.684550     0.684634     0.684632     0.684461   \n",
       "4       0.671236     0.670445     0.669661     0.668889     0.668196   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "465     0.699013     0.700283     0.701001     0.701229     0.701127   \n",
       "466     0.693254     0.693763     0.694442     0.695615     0.697754   \n",
       "467     0.686958     0.686474     0.685674     0.684757     0.683837   \n",
       "468     0.652792     0.653381     0.654533     0.656147     0.657785   \n",
       "469     0.739684     0.740548     0.741296     0.741795     0.742056   \n",
       "\n",
       "     current_206  current_207  current_208  current_209  current_210  ...  \\\n",
       "0       0.680484     0.680928     0.682209     0.683694     0.684659  ...   \n",
       "1       0.679554     0.680862     0.681912     0.682436     0.682467  ...   \n",
       "2       0.688761     0.687545     0.686558     0.685798     0.685337  ...   \n",
       "3       0.683996     0.683266     0.682420     0.681621     0.680988  ...   \n",
       "4       0.667722     0.667399     0.667360     0.668124     0.669890  ...   \n",
       "..           ...          ...          ...          ...          ...  ...   \n",
       "465     0.700915     0.700716     0.700710     0.700854     0.700750  ...   \n",
       "466     0.700593     0.703291     0.705338     0.706631     0.707332  ...   \n",
       "467     0.683164     0.682842     0.682819     0.683196     0.683973  ...   \n",
       "468     0.659059     0.659839     0.660204     0.660300     0.660191  ...   \n",
       "469     0.742149     0.742147     0.742174     0.742341     0.742520  ...   \n",
       "\n",
       "     volt_791  volt_792  volt_793  volt_794  volt_795  volt_796  volt_797  \\\n",
       "0    0.475171  0.406982  0.367278  0.364093  0.402194  0.448523  0.450469   \n",
       "1    0.313650  0.273656  0.261276  0.271836  0.308600  0.356592  0.389055   \n",
       "2    0.346655  0.317711  0.297014  0.288137  0.302547  0.330311  0.342483   \n",
       "3    0.277664  0.265779  0.276489  0.310451  0.382017  0.485955  0.568265   \n",
       "4    0.474643  0.415693  0.381110  0.376050  0.407861  0.460601  0.481486   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "465  0.164359  0.156490  0.160885  0.174962  0.209262  0.245508  0.258957   \n",
       "466  0.335628  0.430326  0.492045  0.491282  0.453160  0.393129  0.308887   \n",
       "467  0.173705  0.166870  0.171276  0.188868  0.235896  0.324066  0.461164   \n",
       "468  0.193938  0.162887  0.151263  0.158412  0.186152  0.202066  0.179934   \n",
       "469  0.348637  0.317461  0.309872  0.324136  0.363829  0.413066  0.431430   \n",
       "\n",
       "     volt_798  volt_799  volt_800  \n",
       "0    0.356803  0.302953  0.274347  \n",
       "1    0.355631  0.369090  0.410403  \n",
       "2    0.289035  0.271342  0.278585  \n",
       "3    0.505633  0.450684  0.407461  \n",
       "4    0.389891  0.325563  0.281171  \n",
       "..        ...       ...       ...  \n",
       "465  0.223890  0.225651  0.280271  \n",
       "466  0.198685  0.149238  0.125311  \n",
       "467  0.508763  0.510587  0.458503  \n",
       "468  0.118501  0.085939  0.069742  \n",
       "469  0.352381  0.300207  0.265476  \n",
       "\n",
       "[295 rows x 1200 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_201</th>\n",
       "      <th>current_202</th>\n",
       "      <th>current_203</th>\n",
       "      <th>current_204</th>\n",
       "      <th>current_205</th>\n",
       "      <th>current_206</th>\n",
       "      <th>current_207</th>\n",
       "      <th>current_208</th>\n",
       "      <th>current_209</th>\n",
       "      <th>current_210</th>\n",
       "      <th>...</th>\n",
       "      <th>volt_791</th>\n",
       "      <th>volt_792</th>\n",
       "      <th>volt_793</th>\n",
       "      <th>volt_794</th>\n",
       "      <th>volt_795</th>\n",
       "      <th>volt_796</th>\n",
       "      <th>volt_797</th>\n",
       "      <th>volt_798</th>\n",
       "      <th>volt_799</th>\n",
       "      <th>volt_800</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.691468</td>\n",
       "      <td>0.691919</td>\n",
       "      <td>0.691857</td>\n",
       "      <td>0.691331</td>\n",
       "      <td>0.690484</td>\n",
       "      <td>0.689532</td>\n",
       "      <td>0.688726</td>\n",
       "      <td>0.688130</td>\n",
       "      <td>0.687714</td>\n",
       "      <td>0.687552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403621</td>\n",
       "      <td>0.342177</td>\n",
       "      <td>0.314036</td>\n",
       "      <td>0.318342</td>\n",
       "      <td>0.356268</td>\n",
       "      <td>0.401804</td>\n",
       "      <td>0.407339</td>\n",
       "      <td>0.316755</td>\n",
       "      <td>0.256458</td>\n",
       "      <td>0.221252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.689295</td>\n",
       "      <td>0.688282</td>\n",
       "      <td>0.687451</td>\n",
       "      <td>0.686783</td>\n",
       "      <td>0.686297</td>\n",
       "      <td>0.686016</td>\n",
       "      <td>0.686165</td>\n",
       "      <td>0.687262</td>\n",
       "      <td>0.689330</td>\n",
       "      <td>0.691714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323495</td>\n",
       "      <td>0.293242</td>\n",
       "      <td>0.277765</td>\n",
       "      <td>0.266636</td>\n",
       "      <td>0.272530</td>\n",
       "      <td>0.298734</td>\n",
       "      <td>0.329949</td>\n",
       "      <td>0.307095</td>\n",
       "      <td>0.308849</td>\n",
       "      <td>0.322219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.704625</td>\n",
       "      <td>0.703717</td>\n",
       "      <td>0.703216</td>\n",
       "      <td>0.703154</td>\n",
       "      <td>0.703356</td>\n",
       "      <td>0.703613</td>\n",
       "      <td>0.703891</td>\n",
       "      <td>0.704373</td>\n",
       "      <td>0.705145</td>\n",
       "      <td>0.705897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235213</td>\n",
       "      <td>0.212009</td>\n",
       "      <td>0.232290</td>\n",
       "      <td>0.283721</td>\n",
       "      <td>0.357671</td>\n",
       "      <td>0.427205</td>\n",
       "      <td>0.455655</td>\n",
       "      <td>0.389299</td>\n",
       "      <td>0.366152</td>\n",
       "      <td>0.376777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.702460</td>\n",
       "      <td>0.702957</td>\n",
       "      <td>0.704118</td>\n",
       "      <td>0.705578</td>\n",
       "      <td>0.706766</td>\n",
       "      <td>0.707387</td>\n",
       "      <td>0.707607</td>\n",
       "      <td>0.707736</td>\n",
       "      <td>0.707861</td>\n",
       "      <td>0.707882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455123</td>\n",
       "      <td>0.387404</td>\n",
       "      <td>0.347294</td>\n",
       "      <td>0.338249</td>\n",
       "      <td>0.361233</td>\n",
       "      <td>0.389561</td>\n",
       "      <td>0.377679</td>\n",
       "      <td>0.282076</td>\n",
       "      <td>0.228494</td>\n",
       "      <td>0.216340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.710469</td>\n",
       "      <td>0.708822</td>\n",
       "      <td>0.707448</td>\n",
       "      <td>0.706760</td>\n",
       "      <td>0.706676</td>\n",
       "      <td>0.706796</td>\n",
       "      <td>0.706901</td>\n",
       "      <td>0.706971</td>\n",
       "      <td>0.707142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306752</td>\n",
       "      <td>0.308216</td>\n",
       "      <td>0.310868</td>\n",
       "      <td>0.323062</td>\n",
       "      <td>0.364767</td>\n",
       "      <td>0.443387</td>\n",
       "      <td>0.525665</td>\n",
       "      <td>0.484873</td>\n",
       "      <td>0.442928</td>\n",
       "      <td>0.400778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.655160</td>\n",
       "      <td>0.654703</td>\n",
       "      <td>0.654392</td>\n",
       "      <td>0.654158</td>\n",
       "      <td>0.654086</td>\n",
       "      <td>0.654370</td>\n",
       "      <td>0.655265</td>\n",
       "      <td>0.656777</td>\n",
       "      <td>0.658473</td>\n",
       "      <td>0.659922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118411</td>\n",
       "      <td>0.085348</td>\n",
       "      <td>0.067686</td>\n",
       "      <td>0.062863</td>\n",
       "      <td>0.078773</td>\n",
       "      <td>0.102914</td>\n",
       "      <td>0.117693</td>\n",
       "      <td>0.097859</td>\n",
       "      <td>0.085690</td>\n",
       "      <td>0.079646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.688720</td>\n",
       "      <td>0.691066</td>\n",
       "      <td>0.693366</td>\n",
       "      <td>0.695296</td>\n",
       "      <td>0.696822</td>\n",
       "      <td>0.698040</td>\n",
       "      <td>0.699004</td>\n",
       "      <td>0.699738</td>\n",
       "      <td>0.700179</td>\n",
       "      <td>0.700178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.267515</td>\n",
       "      <td>0.243962</td>\n",
       "      <td>0.250543</td>\n",
       "      <td>0.279990</td>\n",
       "      <td>0.333953</td>\n",
       "      <td>0.393716</td>\n",
       "      <td>0.419058</td>\n",
       "      <td>0.355549</td>\n",
       "      <td>0.327488</td>\n",
       "      <td>0.312347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.717838</td>\n",
       "      <td>0.716938</td>\n",
       "      <td>0.715976</td>\n",
       "      <td>0.714911</td>\n",
       "      <td>0.713888</td>\n",
       "      <td>0.712956</td>\n",
       "      <td>0.711976</td>\n",
       "      <td>0.710904</td>\n",
       "      <td>0.709947</td>\n",
       "      <td>0.709364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300854</td>\n",
       "      <td>0.269906</td>\n",
       "      <td>0.262787</td>\n",
       "      <td>0.261464</td>\n",
       "      <td>0.268023</td>\n",
       "      <td>0.270470</td>\n",
       "      <td>0.250558</td>\n",
       "      <td>0.187487</td>\n",
       "      <td>0.160850</td>\n",
       "      <td>0.156544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.671228</td>\n",
       "      <td>0.671696</td>\n",
       "      <td>0.671971</td>\n",
       "      <td>0.672160</td>\n",
       "      <td>0.672397</td>\n",
       "      <td>0.672658</td>\n",
       "      <td>0.672790</td>\n",
       "      <td>0.672632</td>\n",
       "      <td>0.672193</td>\n",
       "      <td>0.671623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149968</td>\n",
       "      <td>0.143442</td>\n",
       "      <td>0.139477</td>\n",
       "      <td>0.127960</td>\n",
       "      <td>0.122262</td>\n",
       "      <td>0.118875</td>\n",
       "      <td>0.110584</td>\n",
       "      <td>0.083422</td>\n",
       "      <td>0.073359</td>\n",
       "      <td>0.071337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.722550</td>\n",
       "      <td>0.721452</td>\n",
       "      <td>0.720337</td>\n",
       "      <td>0.719178</td>\n",
       "      <td>0.717978</td>\n",
       "      <td>0.716881</td>\n",
       "      <td>0.715988</td>\n",
       "      <td>0.715285</td>\n",
       "      <td>0.714784</td>\n",
       "      <td>0.714635</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169253</td>\n",
       "      <td>0.158205</td>\n",
       "      <td>0.208111</td>\n",
       "      <td>0.335710</td>\n",
       "      <td>0.476410</td>\n",
       "      <td>0.531009</td>\n",
       "      <td>0.470152</td>\n",
       "      <td>0.308952</td>\n",
       "      <td>0.213821</td>\n",
       "      <td>0.165598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows × 1200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     current_201  current_202  current_203  current_204  current_205  \\\n",
       "125     0.691468     0.691919     0.691857     0.691331     0.690484   \n",
       "126     0.689295     0.688282     0.687451     0.686783     0.686297   \n",
       "127     0.704625     0.703717     0.703216     0.703154     0.703356   \n",
       "128     0.702460     0.702957     0.704118     0.705578     0.706766   \n",
       "129     0.711864     0.710469     0.708822     0.707448     0.706760   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "474     0.655160     0.654703     0.654392     0.654158     0.654086   \n",
       "475     0.688720     0.691066     0.693366     0.695296     0.696822   \n",
       "476     0.717838     0.716938     0.715976     0.714911     0.713888   \n",
       "477     0.671228     0.671696     0.671971     0.672160     0.672397   \n",
       "478     0.722550     0.721452     0.720337     0.719178     0.717978   \n",
       "\n",
       "     current_206  current_207  current_208  current_209  current_210  ...  \\\n",
       "125     0.689532     0.688726     0.688130     0.687714     0.687552  ...   \n",
       "126     0.686016     0.686165     0.687262     0.689330     0.691714  ...   \n",
       "127     0.703613     0.703891     0.704373     0.705145     0.705897  ...   \n",
       "128     0.707387     0.707607     0.707736     0.707861     0.707882  ...   \n",
       "129     0.706676     0.706796     0.706901     0.706971     0.707142  ...   \n",
       "..           ...          ...          ...          ...          ...  ...   \n",
       "474     0.654370     0.655265     0.656777     0.658473     0.659922  ...   \n",
       "475     0.698040     0.699004     0.699738     0.700179     0.700178  ...   \n",
       "476     0.712956     0.711976     0.710904     0.709947     0.709364  ...   \n",
       "477     0.672658     0.672790     0.672632     0.672193     0.671623  ...   \n",
       "478     0.716881     0.715988     0.715285     0.714784     0.714635  ...   \n",
       "\n",
       "     volt_791  volt_792  volt_793  volt_794  volt_795  volt_796  volt_797  \\\n",
       "125  0.403621  0.342177  0.314036  0.318342  0.356268  0.401804  0.407339   \n",
       "126  0.323495  0.293242  0.277765  0.266636  0.272530  0.298734  0.329949   \n",
       "127  0.235213  0.212009  0.232290  0.283721  0.357671  0.427205  0.455655   \n",
       "128  0.455123  0.387404  0.347294  0.338249  0.361233  0.389561  0.377679   \n",
       "129  0.306752  0.308216  0.310868  0.323062  0.364767  0.443387  0.525665   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "474  0.118411  0.085348  0.067686  0.062863  0.078773  0.102914  0.117693   \n",
       "475  0.267515  0.243962  0.250543  0.279990  0.333953  0.393716  0.419058   \n",
       "476  0.300854  0.269906  0.262787  0.261464  0.268023  0.270470  0.250558   \n",
       "477  0.149968  0.143442  0.139477  0.127960  0.122262  0.118875  0.110584   \n",
       "478  0.169253  0.158205  0.208111  0.335710  0.476410  0.531009  0.470152   \n",
       "\n",
       "     volt_798  volt_799  volt_800  \n",
       "125  0.316755  0.256458  0.221252  \n",
       "126  0.307095  0.308849  0.322219  \n",
       "127  0.389299  0.366152  0.376777  \n",
       "128  0.282076  0.228494  0.216340  \n",
       "129  0.484873  0.442928  0.400778  \n",
       "..        ...       ...       ...  \n",
       "474  0.097859  0.085690  0.079646  \n",
       "475  0.355549  0.327488  0.312347  \n",
       "476  0.187487  0.160850  0.156544  \n",
       "477  0.083422  0.073359  0.071337  \n",
       "478  0.308952  0.213821  0.165598  \n",
       "\n",
       "[184 rows x 1200 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = True\n",
    "ann = MLPClassifier(\n",
    "    hidden_layer_sizes=(150, 300),\n",
    "    max_iter=300,\n",
    "    tol=0.0000000001,\n",
    "    learning_rate_init=0.01,\n",
    "    solver='adam',\n",
    "    activation='relu',\n",
    "    learning_rate='constant',\n",
    "    verbose=True,\n",
    "    early_stopping=early_stopping, # needed to get validation_scores stats\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4.15213021\n",
      "Validation score: 0.700000\n",
      "Iteration 2, loss = 2.80304176\n",
      "Validation score: 0.366667\n",
      "Iteration 3, loss = 3.21211814\n",
      "Validation score: 0.300000\n",
      "Iteration 4, loss = 2.11979429\n",
      "Validation score: 0.700000\n",
      "Iteration 5, loss = 0.72965070\n",
      "Validation score: 0.700000\n",
      "Iteration 6, loss = 0.60050921\n",
      "Validation score: 0.733333\n",
      "Iteration 7, loss = 0.40976723\n",
      "Validation score: 0.833333\n",
      "Iteration 8, loss = 0.36441574\n",
      "Validation score: 0.800000\n",
      "Iteration 9, loss = 0.46923845\n",
      "Validation score: 0.833333\n",
      "Iteration 10, loss = 0.38521390\n",
      "Validation score: 0.966667\n",
      "Iteration 11, loss = 0.29317432\n",
      "Validation score: 0.733333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 12, loss = 0.38358716\n",
      "Validation score: 0.933333\n",
      "Iteration 13, loss = 0.29866339\n",
      "Validation score: 0.966667\n",
      "Iteration 14, loss = 0.28090380\n",
      "Validation score: 0.833333\n",
      "Iteration 15, loss = 0.28165542\n",
      "Validation score: 0.833333\n",
      "Iteration 16, loss = 0.23825382\n",
      "Validation score: 0.866667\n",
      "Iteration 17, loss = 0.29060294\n",
      "Validation score: 0.833333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18, loss = 0.22897793\n",
      "Validation score: 1.000000\n",
      "Iteration 19, loss = 0.18205188\n",
      "Validation score: 1.000000\n",
      "Iteration 20, loss = 0.14805324\n",
      "Validation score: 0.833333\n",
      "Iteration 21, loss = 0.15008023\n",
      "Validation score: 1.000000\n",
      "Iteration 22, loss = 0.11979240\n",
      "Validation score: 0.866667\n",
      "Iteration 23, loss = 0.11958182\n",
      "Validation score: 1.000000\n",
      "Iteration 24, loss = 0.09611816\n",
      "Validation score: 1.000000\n",
      "Iteration 25, loss = 0.07663355\n",
      "Validation score: 0.866667\n",
      "Iteration 26, loss = 0.10166236\n",
      "Validation score: 1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27, loss = 0.08808415\n",
      "Validation score: 0.900000\n",
      "Iteration 28, loss = 0.10304617\n",
      "Validation score: 1.000000\n",
      "Iteration 29, loss = 0.08428451\n",
      "Validation score: 1.000000\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/pedro/Brincadeiras/facul/ia/ann-engine/venv/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(150, 300),\n",
       "              learning_rate_init=0.01, max_iter=300, tol=1e-10, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(150, 300),\n",
       "              learning_rate_init=0.01, max_iter=300, tol=1e-10, verbose=True)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(early_stopping=True, hidden_layer_sizes=(150, 300),\n",
       "              learning_rate_init=0.01, max_iter=300, tol=1e-10, verbose=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the model is well fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if early_stopping:\n",
    "    loss_train = ann.loss_curve_\n",
    "    loss_validation = ann.validation_scores_\n",
    "\n",
    "    loss_train_df = pd.DataFrame(\n",
    "        {\n",
    "            'loss': loss_train,\n",
    "            'iterations': [x for x in range(len(loss_train))]\n",
    "        }\n",
    "    )\n",
    "    loss_train_df['Data'] = 'Training'\n",
    "\n",
    "    loss_validation_df = pd.DataFrame(\n",
    "        {\n",
    "            'loss': [1 - x for x in loss_validation],\n",
    "            'iterations': [x for x in range(len(loss_validation))]\n",
    "        }\n",
    "    )\n",
    "    loss_validation_df['Data'] = 'Validation'\n",
    "\n",
    "    loss_df = pd.concat([loss_train_df, loss_validation_df])\n",
    "\n",
    "    sns.lineplot(data=loss_df, x='iterations', y='loss', hue='Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot showed that the model is well fitted as the loss from validation and training datasets are nearly the same in the end of fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.00%\n"
     ]
    }
   ],
   "source": [
    "score = ann.score(X_test, y_test)\n",
    "y_pred = ann.predict(X_test)\n",
    "\n",
    "\n",
    "print('%.2f' %(score*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the probability for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of a random sample of state 0: [[0.8322 0.     0.1678]]\n",
      "Probability of a random sample of state 1: [[0.000e+00 9.999e-01 1.000e-04]]\n",
      "Probability of a random sample of state 2: [[0.203  0.0032 0.7939]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Probability of a random sample of state 0:\", np.round(ann.predict_proba(X_test_0[:1]), 4) )\n",
    "print(\"Probability of a random sample of state 1:\", np.round(ann.predict_proba(X_test_1[:1]), 4) )\n",
    "print(\"Probability of a random sample of state 2:\", np.round(ann.predict_proba(X_test_2[:1]), 4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN Characteristics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.0001,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': True,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (150, 300),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.01,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 300,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': None,\n",
       " 'shuffle': True,\n",
       " 'solver': 'adam',\n",
       " 'tol': 1e-10,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': True,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.get_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c00d594dade041c07c65151f11049b96387fcc7bcfd07780fd4f8feb49b14c80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
